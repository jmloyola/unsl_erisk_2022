{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.config import PATH_BEST_MODELS, PICKLE_PROTOCOL  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_KIND = \"reddit\"\n",
    "CORPUS_NAME = \"gambling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disabled-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_best_models(corpus_name, corpus_kind, measure=\"positive_f1\"):\n",
    "    base_path = os.path.join(PATH_BEST_MODELS, measure, corpus_kind, corpus_name)\n",
    "    suffix = \".pkl\"\n",
    "    possible_files = glob.glob(f\"{base_path}/result_comparison_*{suffix}\")\n",
    "    last_date = None\n",
    "\n",
    "    for file in possible_files:\n",
    "        date_str_sup_lim = -len(suffix)\n",
    "        date_str_inf_lim = -(len(suffix) + len(\"2020_10_26\"))  # Random date\n",
    "        date_str = file[date_str_inf_lim:date_str_sup_lim]\n",
    "        current_date = datetime.datetime.strptime(date_str, \"%Y_%m_%d\")\n",
    "\n",
    "        if last_date is None or last_date < current_date:\n",
    "            last_date = current_date\n",
    "\n",
    "    if last_date is None:\n",
    "        print(\"No file with the best models run was found.\")\n",
    "        return None\n",
    "    file_path = os.path.join(\n",
    "        base_path, f'result_comparison_{last_date.strftime(\"%Y_%m_%d\")}{suffix}'\n",
    "    )\n",
    "    print(\n",
    "        f\"Loading the DataFrame with the best models for the measure {measure}: {file_path}.\"\n",
    "    )\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        dataframe = pickle.load(f)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "single-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DataFrame with the best models for the measure positive_f1: /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/result_comparison_2022_06_10.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_identifier</th>\n",
       "      <th>corpus_kind</th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>representation</th>\n",
       "      <th>representation_information</th>\n",
       "      <th>train_file_path</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>classifier_type</th>\n",
       "      <th>classifier_params</th>\n",
       "      <th>classification_report</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>elapsed_mins</th>\n",
       "      <th>elapsed_secs</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>file_name</th>\n",
       "      <th>current_measure</th>\n",
       "      <th>positive_recall</th>\n",
       "      <th>positive_precision</th>\n",
       "      <th>positive_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'char_...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/processed/...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 32, 'break_ties': False, 'cache_size': 2...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>[[542, 2], [18, 186]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0178_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'char_...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/processed/...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958556</td>\n",
       "      <td>[[532, 12], [19, 185]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0057_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'char_...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/processed/...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 128, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975936</td>\n",
       "      <td>[[542, 2], [16, 188]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0086_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>743.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'char_...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/processed/...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 128, 'class_weight': 'balanced', 'dual':...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975936</td>\n",
       "      <td>[[542, 2], [16, 188]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0062_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>744.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'word'...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/processed/...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.0001, 'batch...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967914</td>\n",
       "      <td>[[537, 7], [17, 187]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0119_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/interim/re...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923797</td>\n",
       "      <td>[[515, 29], [28, 176]]</td>\n",
       "      <td>369.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22176.0</td>\n",
       "      <td>15_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>1476.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/interim/re...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923797</td>\n",
       "      <td>[[519, 25], [32, 172]]</td>\n",
       "      <td>386.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23188.0</td>\n",
       "      <td>07_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>1477.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/interim/re...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919786</td>\n",
       "      <td>[[511, 33], [27, 177]]</td>\n",
       "      <td>377.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22645.0</td>\n",
       "      <td>10_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1478.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/interim/re...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922460</td>\n",
       "      <td>[[517, 27], [31, 173]]</td>\n",
       "      <td>383.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>23032.0</td>\n",
       "      <td>01_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1479.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>gambling</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home/jmloyola/unsl_erisk_2022/data/interim/re...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923797</td>\n",
       "      <td>[[514, 30], [27, 177]]</td>\n",
       "      <td>374.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22463.0</td>\n",
       "      <td>13_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_identifier corpus_kind corpus_name  representation  \\\n",
       "740              740.0      reddit    gambling             bow   \n",
       "741              741.0      reddit    gambling             bow   \n",
       "742              742.0      reddit    gambling             bow   \n",
       "743              743.0      reddit    gambling             bow   \n",
       "744              744.0      reddit    gambling             bow   \n",
       "...                ...         ...         ...             ...   \n",
       "1475            1475.0      reddit    gambling  bert_tokenizer   \n",
       "1476            1476.0      reddit    gambling  bert_tokenizer   \n",
       "1477            1477.0      reddit    gambling  bert_tokenizer   \n",
       "1478            1478.0      reddit    gambling  bert_tokenizer   \n",
       "1479            1479.0      reddit    gambling  bert_tokenizer   \n",
       "\n",
       "                             representation_information  \\\n",
       "740   {'CountVectorizer_params': {'analyzer': 'char_...   \n",
       "741   {'CountVectorizer_params': {'analyzer': 'char_...   \n",
       "742   {'CountVectorizer_params': {'analyzer': 'char_...   \n",
       "743   {'CountVectorizer_params': {'analyzer': 'char_...   \n",
       "744   {'CountVectorizer_params': {'analyzer': 'word'...   \n",
       "...                                                 ...   \n",
       "1475  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1476  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1477  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1478  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1479  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "\n",
       "                                        train_file_path  random_seed  \\\n",
       "740   /home/jmloyola/unsl_erisk_2022/data/processed/...         28.0   \n",
       "741   /home/jmloyola/unsl_erisk_2022/data/processed/...         27.0   \n",
       "742   /home/jmloyola/unsl_erisk_2022/data/processed/...         26.0   \n",
       "743   /home/jmloyola/unsl_erisk_2022/data/processed/...          2.0   \n",
       "744   /home/jmloyola/unsl_erisk_2022/data/processed/...         29.0   \n",
       "...                                                 ...          ...   \n",
       "1475  /home/jmloyola/unsl_erisk_2022/data/interim/re...         15.0   \n",
       "1476  /home/jmloyola/unsl_erisk_2022/data/interim/re...          7.0   \n",
       "1477  /home/jmloyola/unsl_erisk_2022/data/interim/re...         10.0   \n",
       "1478  /home/jmloyola/unsl_erisk_2022/data/interim/re...          1.0   \n",
       "1479  /home/jmloyola/unsl_erisk_2022/data/interim/re...         13.0   \n",
       "\n",
       "           classifier_type                                  classifier_params  \\\n",
       "740                    SVC  {'C': 32, 'break_ties': False, 'cache_size': 2...   \n",
       "741   KNeighborsClassifier  {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "742     LogisticRegression  {'C': 128, 'class_weight': 'balanced', 'dual':...   \n",
       "743     LogisticRegression  {'C': 128, 'class_weight': 'balanced', 'dual':...   \n",
       "744          MLPClassifier  {'activation': 'relu', 'alpha': 0.0001, 'batch...   \n",
       "...                    ...                                                ...   \n",
       "1475                  BERT  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1476                  BERT  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1477                  BERT  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1478                  BERT  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1479                  BERT  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "\n",
       "                                  classification_report  ...  accuracy  \\\n",
       "740                 precision    recall  f1-score   ...  ...  0.973262   \n",
       "741                 precision    recall  f1-score   ...  ...  0.958556   \n",
       "742                 precision    recall  f1-score   ...  ...  0.975936   \n",
       "743                 precision    recall  f1-score   ...  ...  0.975936   \n",
       "744                 precision    recall  f1-score   ...  ...  0.967914   \n",
       "...                                                 ...  ...       ...   \n",
       "1475                precision    recall  f1-score   ...  ...  0.923797   \n",
       "1476                precision    recall  f1-score   ...  ...  0.923797   \n",
       "1477                precision    recall  f1-score   ...  ...  0.919786   \n",
       "1478                precision    recall  f1-score   ...  ...  0.922460   \n",
       "1479                precision    recall  f1-score   ...  ...  0.923797   \n",
       "\n",
       "            confusion_matrix  elapsed_mins  elapsed_secs total_secs  \\\n",
       "740    [[542, 2], [18, 186]]           0.0          15.0       15.0   \n",
       "741   [[532, 12], [19, 185]]           0.0           2.0        2.0   \n",
       "742    [[542, 2], [16, 188]]           0.0           0.0        0.0   \n",
       "743    [[542, 2], [16, 188]]           0.0           0.0        0.0   \n",
       "744    [[537, 7], [17, 187]]           0.0          11.0       11.0   \n",
       "...                      ...           ...           ...        ...   \n",
       "1475  [[515, 29], [28, 176]]         369.0          36.0    22176.0   \n",
       "1476  [[519, 25], [32, 172]]         386.0          28.0    23188.0   \n",
       "1477  [[511, 33], [27, 177]]         377.0          25.0    22645.0   \n",
       "1478  [[517, 27], [31, 173]]         383.0          52.0    23032.0   \n",
       "1479  [[514, 30], [27, 177]]         374.0          23.0    22463.0   \n",
       "\n",
       "                   file_name  current_measure  positive_recall  \\\n",
       "740   0178_model_information      positive_f1             0.91   \n",
       "741   0057_model_information      positive_f1             0.91   \n",
       "742   0086_model_information      positive_f1             0.92   \n",
       "743   0062_model_information      positive_f1             0.92   \n",
       "744   0119_model_information      positive_f1             0.92   \n",
       "...                      ...              ...              ...   \n",
       "1475    15_model_information      positive_f1             0.86   \n",
       "1476    07_model_information      positive_f1             0.84   \n",
       "1477    10_model_information      positive_f1             0.87   \n",
       "1478    01_model_information      positive_f1             0.85   \n",
       "1479    13_model_information      positive_f1             0.87   \n",
       "\n",
       "     positive_precision positive_f1  \n",
       "740                0.99        0.95  \n",
       "741                0.94        0.92  \n",
       "742                0.99        0.95  \n",
       "743                0.99        0.95  \n",
       "744                0.96        0.94  \n",
       "...                 ...         ...  \n",
       "1475               0.86        0.86  \n",
       "1476               0.87        0.86  \n",
       "1477               0.84        0.86  \n",
       "1478               0.86        0.86  \n",
       "1479               0.86        0.86  \n",
       "\n",
       "[740 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe_best_models(\n",
    "    corpus_name=CORPUS_NAME, corpus_kind=CORPUS_KIND, measure=\"positive_f1\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "falling-right",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "representation     classifier_type       \n",
       "bert_tokenizer     BERT                      0.87\n",
       "bow                DecisionTreeClassifier    0.97\n",
       "                   KNeighborsClassifier      0.92\n",
       "                   LogisticRegression        0.95\n",
       "                   MLPClassifier             0.94\n",
       "                   RandomForestClassifier    0.97\n",
       "                   SVC                       0.95\n",
       "doc2vec            DecisionTreeClassifier    0.80\n",
       "                   KNeighborsClassifier      0.77\n",
       "                   LogisticRegression        0.96\n",
       "                   MLPClassifier             0.95\n",
       "                   RandomForestClassifier    0.89\n",
       "                   SVC                       0.95\n",
       "lda                DecisionTreeClassifier    0.94\n",
       "                   KNeighborsClassifier      0.94\n",
       "                   LogisticRegression        0.95\n",
       "                   MLPClassifier             0.94\n",
       "                   RandomForestClassifier    0.95\n",
       "                   SVC                       0.95\n",
       "lsa                DecisionTreeClassifier    0.90\n",
       "                   KNeighborsClassifier      0.91\n",
       "                   LogisticRegression        0.95\n",
       "                   MLPClassifier             0.96\n",
       "                   RandomForestClassifier    0.92\n",
       "                   SVC                       0.95\n",
       "padded_sequential  EmbeddingLSTM             0.83\n",
       "Name: positive_f1, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=[\"representation\", \"classifier_type\"])[\"positive_f1\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "healthy-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_same_parameters(parameters_dict, input_file):\n",
    "    parameters_dict_json = json.dumps(obj=parameters_dict, sort_keys=True)\n",
    "    with open(input_file) as f:\n",
    "        input_file_json = json.dumps(json.load(fp=f), sort_keys=True)\n",
    "    return input_file_json == parameters_dict_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wicked-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(\n",
    "    model_information, representation_information, measure, corpus_kind, corpus_name\n",
    "):\n",
    "    model_information_file_suffix = \"_model*.json\"\n",
    "    base_path = os.path.join(\n",
    "        PATH_BEST_MODELS, measure, corpus_kind, corpus_name, \"selected_models\"\n",
    "    )\n",
    "\n",
    "    possible_files = glob.glob(f\"{base_path}/*{model_information_file_suffix}\")\n",
    "    max_id = 0\n",
    "    current_id = 0\n",
    "    already_exists = False\n",
    "    for file_path in possible_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        current_id = int(file_name[0:2])\n",
    "        if current_id > max_id:\n",
    "            max_id = current_id\n",
    "        already_exists_model = have_same_parameters(model_information, file_path)\n",
    "        representation_file_path = glob.glob(\n",
    "            f\"{base_path}/{current_id:02d}_representation_*.json\"\n",
    "        )[0]\n",
    "        already_exists_representation = have_same_parameters(\n",
    "            representation_information, representation_file_path\n",
    "        )\n",
    "        already_exists = already_exists_model and already_exists_representation\n",
    "        if already_exists:\n",
    "            print(f\"The model already exists in the path {file_path}.\")\n",
    "            break\n",
    "    model_id = current_id if already_exists else max_id + 1\n",
    "    return model_id, already_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "under-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(\n",
    "    data,\n",
    "    representation,\n",
    "    classifier_type,\n",
    "    corpus_name,\n",
    "    corpus_kind,\n",
    "    measure=\"positive_f1\",\n",
    "):\n",
    "    output_partial_path = os.path.join(\n",
    "        PATH_BEST_MODELS, measure, corpus_kind, corpus_name, \"selected_models\"\n",
    "    )\n",
    "    os.makedirs(output_partial_path, exist_ok=True)\n",
    "\n",
    "    cond1 = data.representation == representation\n",
    "    cond2 = data.classifier_type == classifier_type\n",
    "    selected_data = data[(cond1 & cond2)]\n",
    "\n",
    "    best_model_idx = selected_data.positive_f1.argmax()\n",
    "\n",
    "    best_model = selected_data.iloc[best_model_idx, :]\n",
    "\n",
    "    representation_information = best_model.representation_information\n",
    "    model_information = best_model.classifier_params\n",
    "    train_file_path = best_model.train_file_path\n",
    "    file_name = best_model.file_name\n",
    "\n",
    "    model_id, already_exists = get_id(\n",
    "        model_information=model_information,\n",
    "        representation_information=representation_information,\n",
    "        measure=measure,\n",
    "        corpus_kind=corpus_kind,\n",
    "        corpus_name=corpus_name,\n",
    "    )\n",
    "    if already_exists:\n",
    "        print(\"The model was saved previously.\")\n",
    "        return\n",
    "\n",
    "    model_information_path = os.path.join(\n",
    "        output_partial_path, f\"{model_id:02d}_model_{classifier_type}.json\"\n",
    "    )\n",
    "    print(f\"Saving the model information in {model_information_path}.\")\n",
    "    with open(model_information_path, \"w\") as f:\n",
    "        json.dump(fp=f, obj=model_information, indent=\"\\t\")\n",
    "\n",
    "    representation_information_path = os.path.join(\n",
    "        output_partial_path, f\"{model_id:02d}_representation_{representation}.json\"\n",
    "    )\n",
    "    with open(representation_information_path, \"w\") as f:\n",
    "        json.dump(fp=f, obj=representation_information, indent=\"\\t\")\n",
    "\n",
    "    representation_path = os.path.join(\n",
    "        output_partial_path, f\"{model_id:02d}_representation_{representation}.pkl\"\n",
    "    )\n",
    "    input_representation_path = None\n",
    "\n",
    "    base_path = os.path.join(\n",
    "        PATH_BEST_MODELS, measure, corpus_kind, corpus_name, representation\n",
    "    )\n",
    "    sufix = \"_model_information\"\n",
    "    if classifier_type != \"EmbeddingLSTM\" and classifier_type != \"BERT\":\n",
    "        model_parameters_file_name = file_name[: -len(sufix)] + \"_model_and_report.pkl\"\n",
    "        model_parameters_file_path = os.path.join(base_path, model_parameters_file_name)\n",
    "\n",
    "        with open(model_parameters_file_path, \"rb\") as f:\n",
    "            model, _, _, _, _, _, _, _, _ = pickle.load(f)\n",
    "\n",
    "        model_path = os.path.join(\n",
    "            output_partial_path, f\"{model_id:02d}_model_{classifier_type}.pkl\"\n",
    "        )\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(model, f, protocol=PICKLE_PROTOCOL)\n",
    "\n",
    "        if representation == \"bow\":\n",
    "            input_representation_path = os.path.abspath(\n",
    "                train_file_path[: -len(\"_train.pkl\")] + \"_features_models.pkl\"\n",
    "            )\n",
    "        elif representation == \"lda\" or representation == \"lsa\":\n",
    "            partial_path = os.path.dirname(train_file_path)\n",
    "            other_file_name = os.path.basename(train_file_path)\n",
    "            input_representation_name = other_file_name.replace(\"_corpus_\", \"_model_\")\n",
    "            input_representation_name = (\n",
    "                input_representation_name[: -len(\"_train.pkl\")] + \".pkl\"\n",
    "            )\n",
    "\n",
    "            input_representation_path = os.path.join(\n",
    "                partial_path, input_representation_name\n",
    "            )\n",
    "\n",
    "            files_to_copy = glob.glob(f\"{partial_path}/{input_representation_name}.*\")\n",
    "            for aux_file in files_to_copy:\n",
    "                aux_file_suffix = os.path.basename(aux_file)\n",
    "                aux_file_suffix = aux_file_suffix[\n",
    "                    aux_file_suffix.index(\".pkl\") + len(\".pkl\") :\n",
    "                ]\n",
    "                aux_file_name = os.path.basename(representation_path) + aux_file_suffix\n",
    "\n",
    "                aux_file_new_path = os.path.join(output_partial_path, aux_file_name)\n",
    "\n",
    "                shutil.copy2(aux_file, aux_file_new_path)\n",
    "\n",
    "            id2word_bigram_model_name = input_representation_name.replace(\n",
    "                representation, \"id2word_bigram\"\n",
    "            )\n",
    "            id2word_bigram_model_path = os.path.join(\n",
    "                partial_path, id2word_bigram_model_name\n",
    "            )\n",
    "            print(id2word_bigram_model_path)\n",
    "\n",
    "            new_id2word_bigram_model_name = f\"{model_id:02d}_representation_{representation}_id2word_bigram_model.pkl\"\n",
    "            new_id2word_bigram_model_path = os.path.join(\n",
    "                output_partial_path, new_id2word_bigram_model_name\n",
    "            )\n",
    "\n",
    "            shutil.copy2(id2word_bigram_model_path, new_id2word_bigram_model_path)\n",
    "        elif representation == \"doc2vec\":\n",
    "            input_representation_path = os.path.abspath(\n",
    "                train_file_path[: -len(\"_train.pkl\")] + \".model\"\n",
    "            )\n",
    "\n",
    "        shutil.copy2(input_representation_path, representation_path)\n",
    "    else:\n",
    "        model_parameters_file_name = file_name[: -len(sufix)] + \"_model_parameters.pt\"\n",
    "        model_parameters_file_path = os.path.join(base_path, model_parameters_file_name)\n",
    "        model_path = os.path.join(\n",
    "            output_partial_path, f\"{model_id:02d}_model_{classifier_type}.pt\"\n",
    "        )\n",
    "\n",
    "        shutil.copy2(model_parameters_file_path, model_path)\n",
    "\n",
    "        if classifier_type == \"EmbeddingLSTM\":\n",
    "            partial_path = os.path.dirname(train_file_path)\n",
    "            input_representation_name = os.path.basename(train_file_path)\n",
    "            input_representation_name = (\n",
    "                input_representation_name[: -len(\"_train.pt\")] + \"_vocabulary.pkl\"\n",
    "            )\n",
    "            input_representation_path = os.path.join(\n",
    "                partial_path, input_representation_name\n",
    "            )\n",
    "\n",
    "            shutil.copy2(input_representation_path, representation_path)\n",
    "        else:\n",
    "            with open(representation_path, \"wb\") as f:\n",
    "                pickle.dump(None, f, protocol=PICKLE_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smooth-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/selected_models/01_model_DecisionTreeClassifier.json.\n",
      "Saving the model information in /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/selected_models/02_model_LogisticRegression.json.\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"bow\",\n",
    "    classifier_type=\"DecisionTreeClassifier\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")\n",
    "\n",
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"bow\",\n",
    "    classifier_type=\"LogisticRegression\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secondary-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/selected_models/03_model_LogisticRegression.json.\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"doc2vec\",\n",
    "    classifier_type=\"LogisticRegression\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff967471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/selected_models/04_model_SVC.json.\n",
      "/home/jmloyola/unsl_erisk_2022/data/processed/reddit/gambling/lda/gambling_id2word_bigram_model_15topics.pkl\n",
      "Saving the model information in /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/selected_models/05_model_LogisticRegression.json.\n",
      "/home/jmloyola/unsl_erisk_2022/data/processed/reddit/gambling/lda/gambling_id2word_bigram_model_15topics.pkl\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"lda\",\n",
    "    classifier_type=\"SVC\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")\n",
    "\n",
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"lda\",\n",
    "    classifier_type=\"LogisticRegression\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8acb310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home/jmloyola/unsl_erisk_2022/best_models/positive_f1/reddit/gambling/selected_models/06_model_SVC.json.\n",
      "/home/jmloyola/unsl_erisk_2022/data/processed/reddit/gambling/lsa/gambling_id2word_bigram_model_100factors.pkl\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"lsa\",\n",
    "    classifier_type=\"SVC\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
