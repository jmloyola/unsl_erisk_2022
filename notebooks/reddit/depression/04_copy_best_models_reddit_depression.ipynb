{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.config import PATH_BEST_MODELS, PICKLE_PROTOCOL  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desirable-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_KIND = \"reddit\"\n",
    "CORPUS_NAME = \"depression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "disabled-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_best_models(corpus_name, corpus_kind, measure=\"positive_f1\"):\n",
    "    base_path = os.path.join(PATH_BEST_MODELS, measure, corpus_kind, corpus_name)\n",
    "    suffix = \".pkl\"\n",
    "    possible_files = glob.glob(f\"{base_path}/result_comparison_*{suffix}\")\n",
    "    last_date = None\n",
    "\n",
    "    for file in possible_files:\n",
    "        date_str_sup_lim = -len(suffix)\n",
    "        date_str_inf_lim = -(len(suffix) + len(\"2020_10_26\"))  # Random date\n",
    "        date_str = file[date_str_inf_lim:date_str_sup_lim]\n",
    "        current_date = datetime.datetime.strptime(date_str, \"%Y_%m_%d\")\n",
    "\n",
    "        if last_date is None or last_date < current_date:\n",
    "            last_date = current_date\n",
    "\n",
    "    if last_date is None:\n",
    "        print(\"No file with the best models run was found.\")\n",
    "        return None\n",
    "    file_path = os.path.join(\n",
    "        base_path, f'result_comparison_{last_date.strftime(\"%Y_%m_%d\")}{suffix}'\n",
    "    )\n",
    "    print(\n",
    "        f\"Loading the DataFrame with the best models for the measure {measure}: {file_path}.\"\n",
    "    )\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        dataframe = pickle.load(f)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "single-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the DataFrame with the best models for the measure positive_f1: /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/result_comparison_2022_06_10.pkl.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_identifier</th>\n",
       "      <th>corpus_kind</th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>representation</th>\n",
       "      <th>representation_information</th>\n",
       "      <th>train_file_path</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>classifier_type</th>\n",
       "      <th>classifier_params</th>\n",
       "      <th>classification_report</th>\n",
       "      <th>...</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>elapsed_mins</th>\n",
       "      <th>elapsed_secs</th>\n",
       "      <th>total_secs</th>\n",
       "      <th>file_name</th>\n",
       "      <th>current_measure</th>\n",
       "      <th>positive_recall</th>\n",
       "      <th>positive_precision</th>\n",
       "      <th>positive_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>740.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'word'...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/processed/r...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934880</td>\n",
       "      <td>[[593, 40], [33, 455]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0150_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'char_...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/processed/r...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873327</td>\n",
       "      <td>[[522, 111], [31, 457]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0046_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>742.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'word'...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/processed/r...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>SVC</td>\n",
       "      <td>{'C': 8, 'break_ties': False, 'cache_size': 20...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928635</td>\n",
       "      <td>[[593, 40], [40, 448]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0180_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>743.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'word'...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/processed/r...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930419</td>\n",
       "      <td>[[596, 37], [41, 447]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0148_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>744.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bow</td>\n",
       "      <td>{'CountVectorizer_params': {'analyzer': 'char_...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/processed/r...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 128, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926851</td>\n",
       "      <td>[[589, 44], [38, 450]]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0076_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1475.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/interim/red...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885816</td>\n",
       "      <td>[[548, 85], [43, 445]]</td>\n",
       "      <td>288.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17319.0</td>\n",
       "      <td>09_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>1476.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/interim/red...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884924</td>\n",
       "      <td>[[547, 86], [43, 445]]</td>\n",
       "      <td>287.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17258.0</td>\n",
       "      <td>03_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>1477.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/interim/red...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887600</td>\n",
       "      <td>[[550, 83], [43, 445]]</td>\n",
       "      <td>288.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17321.0</td>\n",
       "      <td>14_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>1478.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/interim/red...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884924</td>\n",
       "      <td>[[548, 85], [44, 444]]</td>\n",
       "      <td>288.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17323.0</td>\n",
       "      <td>08_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>1479.0</td>\n",
       "      <td>reddit</td>\n",
       "      <td>depression</td>\n",
       "      <td>bert_tokenizer</td>\n",
       "      <td>PreTrainedTokenizer(name_or_path='roberta-base...</td>\n",
       "      <td>/home2/loyola/unsl_erisk_2022/data/interim/red...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>BERT</td>\n",
       "      <td>{'model_architecture': 'BERT(\n",
       "  (encoder): Rob...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879572</td>\n",
       "      <td>[[539, 94], [41, 447]]</td>\n",
       "      <td>288.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17293.0</td>\n",
       "      <td>11_model_information</td>\n",
       "      <td>positive_f1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>740 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_identifier corpus_kind corpus_name  representation  \\\n",
       "740              740.0      reddit  depression             bow   \n",
       "741              741.0      reddit  depression             bow   \n",
       "742              742.0      reddit  depression             bow   \n",
       "743              743.0      reddit  depression             bow   \n",
       "744              744.0      reddit  depression             bow   \n",
       "...                ...         ...         ...             ...   \n",
       "1475            1475.0      reddit  depression  bert_tokenizer   \n",
       "1476            1476.0      reddit  depression  bert_tokenizer   \n",
       "1477            1477.0      reddit  depression  bert_tokenizer   \n",
       "1478            1478.0      reddit  depression  bert_tokenizer   \n",
       "1479            1479.0      reddit  depression  bert_tokenizer   \n",
       "\n",
       "                             representation_information  \\\n",
       "740   {'CountVectorizer_params': {'analyzer': 'word'...   \n",
       "741   {'CountVectorizer_params': {'analyzer': 'char_...   \n",
       "742   {'CountVectorizer_params': {'analyzer': 'word'...   \n",
       "743   {'CountVectorizer_params': {'analyzer': 'word'...   \n",
       "744   {'CountVectorizer_params': {'analyzer': 'char_...   \n",
       "...                                                 ...   \n",
       "1475  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1476  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1477  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1478  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "1479  PreTrainedTokenizer(name_or_path='roberta-base...   \n",
       "\n",
       "                                        train_file_path  random_seed  \\\n",
       "740   /home2/loyola/unsl_erisk_2022/data/processed/r...         30.0   \n",
       "741   /home2/loyola/unsl_erisk_2022/data/processed/r...         16.0   \n",
       "742   /home2/loyola/unsl_erisk_2022/data/processed/r...         30.0   \n",
       "743   /home2/loyola/unsl_erisk_2022/data/processed/r...         28.0   \n",
       "744   /home2/loyola/unsl_erisk_2022/data/processed/r...         16.0   \n",
       "...                                                 ...          ...   \n",
       "1475  /home2/loyola/unsl_erisk_2022/data/interim/red...          9.0   \n",
       "1476  /home2/loyola/unsl_erisk_2022/data/interim/red...          3.0   \n",
       "1477  /home2/loyola/unsl_erisk_2022/data/interim/red...         14.0   \n",
       "1478  /home2/loyola/unsl_erisk_2022/data/interim/red...          8.0   \n",
       "1479  /home2/loyola/unsl_erisk_2022/data/interim/red...         11.0   \n",
       "\n",
       "             classifier_type  \\\n",
       "740   RandomForestClassifier   \n",
       "741     KNeighborsClassifier   \n",
       "742                      SVC   \n",
       "743   RandomForestClassifier   \n",
       "744       LogisticRegression   \n",
       "...                      ...   \n",
       "1475                    BERT   \n",
       "1476                    BERT   \n",
       "1477                    BERT   \n",
       "1478                    BERT   \n",
       "1479                    BERT   \n",
       "\n",
       "                                      classifier_params  \\\n",
       "740   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "741   {'algorithm': 'auto', 'leaf_size': 30, 'metric...   \n",
       "742   {'C': 8, 'break_ties': False, 'cache_size': 20...   \n",
       "743   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...   \n",
       "744   {'C': 128, 'class_weight': None, 'dual': False...   \n",
       "...                                                 ...   \n",
       "1475  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1476  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1477  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1478  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "1479  {'model_architecture': 'BERT(\n",
       "  (encoder): Rob...   \n",
       "\n",
       "                                  classification_report  ...  accuracy  \\\n",
       "740                 precision    recall  f1-score   ...  ...  0.934880   \n",
       "741                 precision    recall  f1-score   ...  ...  0.873327   \n",
       "742                 precision    recall  f1-score   ...  ...  0.928635   \n",
       "743                 precision    recall  f1-score   ...  ...  0.930419   \n",
       "744                 precision    recall  f1-score   ...  ...  0.926851   \n",
       "...                                                 ...  ...       ...   \n",
       "1475                precision    recall  f1-score   ...  ...  0.885816   \n",
       "1476                precision    recall  f1-score   ...  ...  0.884924   \n",
       "1477                precision    recall  f1-score   ...  ...  0.887600   \n",
       "1478                precision    recall  f1-score   ...  ...  0.884924   \n",
       "1479                precision    recall  f1-score   ...  ...  0.879572   \n",
       "\n",
       "             confusion_matrix  elapsed_mins  elapsed_secs total_secs  \\\n",
       "740    [[593, 40], [33, 455]]           0.0           1.0        1.0   \n",
       "741   [[522, 111], [31, 457]]           0.0           0.0        0.0   \n",
       "742    [[593, 40], [40, 448]]           0.0          13.0       13.0   \n",
       "743    [[596, 37], [41, 447]]           0.0           1.0        1.0   \n",
       "744    [[589, 44], [38, 450]]           0.0           0.0        0.0   \n",
       "...                       ...           ...           ...        ...   \n",
       "1475   [[548, 85], [43, 445]]         288.0          39.0    17319.0   \n",
       "1476   [[547, 86], [43, 445]]         287.0          38.0    17258.0   \n",
       "1477   [[550, 83], [43, 445]]         288.0          41.0    17321.0   \n",
       "1478   [[548, 85], [44, 444]]         288.0          43.0    17323.0   \n",
       "1479   [[539, 94], [41, 447]]         288.0          13.0    17293.0   \n",
       "\n",
       "                   file_name  current_measure  positive_recall  \\\n",
       "740   0150_model_information      positive_f1             0.93   \n",
       "741   0046_model_information      positive_f1             0.94   \n",
       "742   0180_model_information      positive_f1             0.92   \n",
       "743   0148_model_information      positive_f1             0.92   \n",
       "744   0076_model_information      positive_f1             0.92   \n",
       "...                      ...              ...              ...   \n",
       "1475    09_model_information      positive_f1             0.91   \n",
       "1476    03_model_information      positive_f1             0.91   \n",
       "1477    14_model_information      positive_f1             0.91   \n",
       "1478    08_model_information      positive_f1             0.91   \n",
       "1479    11_model_information      positive_f1             0.92   \n",
       "\n",
       "     positive_precision positive_f1  \n",
       "740                0.92        0.93  \n",
       "741                0.80        0.87  \n",
       "742                0.92        0.92  \n",
       "743                0.92        0.92  \n",
       "744                0.91        0.92  \n",
       "...                 ...         ...  \n",
       "1475               0.84        0.87  \n",
       "1476               0.84        0.87  \n",
       "1477               0.84        0.88  \n",
       "1478               0.84        0.87  \n",
       "1479               0.83        0.87  \n",
       "\n",
       "[740 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_dataframe_best_models(\n",
    "    corpus_name=CORPUS_NAME, corpus_kind=CORPUS_KIND, measure=\"positive_f1\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "falling-right",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "representation     classifier_type       \n",
       "bert_tokenizer     BERT                      0.88\n",
       "bow                DecisionTreeClassifier    0.90\n",
       "                   KNeighborsClassifier      0.87\n",
       "                   LogisticRegression        0.92\n",
       "                   MLPClassifier             0.91\n",
       "                   RandomForestClassifier    0.93\n",
       "                   SVC                       0.92\n",
       "doc2vec            DecisionTreeClassifier    0.82\n",
       "                   KNeighborsClassifier      0.71\n",
       "                   LogisticRegression        0.92\n",
       "                   MLPClassifier             0.92\n",
       "                   RandomForestClassifier    0.90\n",
       "                   SVC                       0.91\n",
       "lda                DecisionTreeClassifier    0.89\n",
       "                   KNeighborsClassifier      0.90\n",
       "                   LogisticRegression        0.90\n",
       "                   MLPClassifier             0.92\n",
       "                   RandomForestClassifier    0.92\n",
       "                   SVC                       0.91\n",
       "lsa                DecisionTreeClassifier    0.85\n",
       "                   KNeighborsClassifier      0.89\n",
       "                   LogisticRegression        0.92\n",
       "                   MLPClassifier             0.91\n",
       "                   RandomForestClassifier    0.91\n",
       "                   SVC                       0.91\n",
       "padded_sequential  EmbeddingLSTM             0.85\n",
       "Name: positive_f1, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(by=[\"representation\", \"classifier_type\"])[\"positive_f1\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "healthy-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_same_parameters(parameters_dict, input_file):\n",
    "    parameters_dict_json = json.dumps(obj=parameters_dict, sort_keys=True)\n",
    "    with open(input_file) as f:\n",
    "        input_file_json = json.dumps(json.load(fp=f), sort_keys=True)\n",
    "    return input_file_json == parameters_dict_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wicked-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(\n",
    "    model_information, representation_information, measure, corpus_kind, corpus_name\n",
    "):\n",
    "    model_information_file_suffix = \"_model*.json\"\n",
    "    base_path = os.path.join(\n",
    "        PATH_BEST_MODELS, measure, corpus_kind, corpus_name, \"selected_models\"\n",
    "    )\n",
    "\n",
    "    possible_files = glob.glob(f\"{base_path}/*{model_information_file_suffix}\")\n",
    "    max_id = 0\n",
    "    current_id = 0\n",
    "    already_exists = False\n",
    "    for file_path in possible_files:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        current_id = int(file_name[0:2])\n",
    "        if current_id > max_id:\n",
    "            max_id = current_id\n",
    "        already_exists_model = have_same_parameters(model_information, file_path)\n",
    "        representation_file_path = glob.glob(\n",
    "            f\"{base_path}/{current_id:02d}_representation_*.json\"\n",
    "        )[0]\n",
    "        already_exists_representation = have_same_parameters(\n",
    "            representation_information, representation_file_path\n",
    "        )\n",
    "        already_exists = already_exists_model and already_exists_representation\n",
    "        if already_exists:\n",
    "            print(f\"The model already exists in the path {file_path}.\")\n",
    "            break\n",
    "    model_id = current_id if already_exists else max_id + 1\n",
    "    return model_id, already_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "under-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(\n",
    "    data,\n",
    "    representation,\n",
    "    classifier_type,\n",
    "    corpus_name,\n",
    "    corpus_kind,\n",
    "    measure=\"positive_f1\",\n",
    "):\n",
    "    output_partial_path = os.path.join(\n",
    "        PATH_BEST_MODELS, measure, corpus_kind, corpus_name, \"selected_models\"\n",
    "    )\n",
    "    os.makedirs(output_partial_path, exist_ok=True)\n",
    "\n",
    "    cond1 = data.representation == representation\n",
    "    cond2 = data.classifier_type == classifier_type\n",
    "    selected_data = data[(cond1 & cond2)]\n",
    "\n",
    "    best_model_idx = selected_data.positive_f1.argmax()\n",
    "\n",
    "    best_model = selected_data.iloc[best_model_idx, :]\n",
    "\n",
    "    representation_information = best_model.representation_information\n",
    "    model_information = best_model.classifier_params\n",
    "    train_file_path = best_model.train_file_path\n",
    "    file_name = best_model.file_name\n",
    "\n",
    "    model_id, already_exists = get_id(\n",
    "        model_information=model_information,\n",
    "        representation_information=representation_information,\n",
    "        measure=measure,\n",
    "        corpus_kind=corpus_kind,\n",
    "        corpus_name=corpus_name,\n",
    "    )\n",
    "    if already_exists:\n",
    "        print(\"The model was saved previously.\")\n",
    "        return\n",
    "\n",
    "    model_information_path = os.path.join(\n",
    "        output_partial_path, f\"{model_id:02d}_model_{classifier_type}.json\"\n",
    "    )\n",
    "    print(f\"Saving the model information in {model_information_path}.\")\n",
    "    with open(model_information_path, \"w\") as f:\n",
    "        json.dump(fp=f, obj=model_information, indent=\"\\t\")\n",
    "\n",
    "    representation_information_path = os.path.join(\n",
    "        output_partial_path, f\"{model_id:02d}_representation_{representation}.json\"\n",
    "    )\n",
    "    with open(representation_information_path, \"w\") as f:\n",
    "        json.dump(fp=f, obj=representation_information, indent=\"\\t\")\n",
    "\n",
    "    representation_path = os.path.join(\n",
    "        output_partial_path, f\"{model_id:02d}_representation_{representation}.pkl\"\n",
    "    )\n",
    "    input_representation_path = None\n",
    "\n",
    "    base_path = os.path.join(\n",
    "        PATH_BEST_MODELS, measure, corpus_kind, corpus_name, representation\n",
    "    )\n",
    "    sufix = \"_model_information\"\n",
    "    if classifier_type != \"EmbeddingLSTM\" and classifier_type != \"BERT\":\n",
    "        model_parameters_file_name = file_name[: -len(sufix)] + \"_model_and_report.pkl\"\n",
    "        model_parameters_file_path = os.path.join(base_path, model_parameters_file_name)\n",
    "\n",
    "        with open(model_parameters_file_path, \"rb\") as f:\n",
    "            model, _, _, _, _, _, _, _, _ = pickle.load(f)\n",
    "\n",
    "        model_path = os.path.join(\n",
    "            output_partial_path, f\"{model_id:02d}_model_{classifier_type}.pkl\"\n",
    "        )\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(model, f, protocol=PICKLE_PROTOCOL)\n",
    "\n",
    "        if representation == \"bow\":\n",
    "            input_representation_path = os.path.abspath(\n",
    "                train_file_path[: -len(\"_train.pkl\")] + \"_features_models.pkl\"\n",
    "            )\n",
    "        elif representation == \"lda\" or representation == \"lsa\":\n",
    "            partial_path = os.path.dirname(train_file_path)\n",
    "            other_file_name = os.path.basename(train_file_path)\n",
    "            input_representation_name = other_file_name.replace(\"_corpus_\", \"_model_\")\n",
    "            input_representation_name = (\n",
    "                input_representation_name[: -len(\"_train.pkl\")] + \".pkl\"\n",
    "            )\n",
    "\n",
    "            input_representation_path = os.path.join(\n",
    "                partial_path, input_representation_name\n",
    "            )\n",
    "\n",
    "            files_to_copy = glob.glob(f\"{partial_path}/{input_representation_name}.*\")\n",
    "            for aux_file in files_to_copy:\n",
    "                aux_file_suffix = os.path.basename(aux_file)\n",
    "                aux_file_suffix = aux_file_suffix[\n",
    "                    aux_file_suffix.index(\".pkl\") + len(\".pkl\") :\n",
    "                ]\n",
    "                aux_file_name = os.path.basename(representation_path) + aux_file_suffix\n",
    "\n",
    "                aux_file_new_path = os.path.join(output_partial_path, aux_file_name)\n",
    "\n",
    "                shutil.copy2(aux_file, aux_file_new_path)\n",
    "\n",
    "            id2word_bigram_model_name = input_representation_name.replace(\n",
    "                representation, \"id2word_bigram\"\n",
    "            )\n",
    "            id2word_bigram_model_path = os.path.join(\n",
    "                partial_path, id2word_bigram_model_name\n",
    "            )\n",
    "            print(id2word_bigram_model_path)\n",
    "\n",
    "            new_id2word_bigram_model_name = f\"{model_id:02d}_representation_{representation}_id2word_bigram_model.pkl\"\n",
    "            new_id2word_bigram_model_path = os.path.join(\n",
    "                output_partial_path, new_id2word_bigram_model_name\n",
    "            )\n",
    "\n",
    "            shutil.copy2(id2word_bigram_model_path, new_id2word_bigram_model_path)\n",
    "        elif representation == \"doc2vec\":\n",
    "            input_representation_path = os.path.abspath(\n",
    "                train_file_path[: -len(\"_train.pkl\")] + \".model\"\n",
    "            )\n",
    "\n",
    "        shutil.copy2(input_representation_path, representation_path)\n",
    "    else:\n",
    "        model_parameters_file_name = file_name[: -len(sufix)] + \"_model_parameters.pt\"\n",
    "        model_parameters_file_path = os.path.join(base_path, model_parameters_file_name)\n",
    "        model_path = os.path.join(\n",
    "            output_partial_path, f\"{model_id:02d}_model_{classifier_type}.pt\"\n",
    "        )\n",
    "\n",
    "        shutil.copy2(model_parameters_file_path, model_path)\n",
    "\n",
    "        if classifier_type == \"EmbeddingLSTM\":\n",
    "            partial_path = os.path.dirname(train_file_path)\n",
    "            input_representation_name = os.path.basename(train_file_path)\n",
    "            input_representation_name = (\n",
    "                input_representation_name[: -len(\"_train.pt\")] + \"_vocabulary.pkl\"\n",
    "            )\n",
    "            input_representation_path = os.path.join(\n",
    "                partial_path, input_representation_name\n",
    "            )\n",
    "\n",
    "            shutil.copy2(input_representation_path, representation_path)\n",
    "        else:\n",
    "            with open(representation_path, \"wb\") as f:\n",
    "                pickle.dump(None, f, protocol=PICKLE_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smooth-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/selected_models/01_model_LogisticRegression.json.\n",
      "Saving the model information in /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/selected_models/02_model_RandomForestClassifier.json.\n",
      "Saving the model information in /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/selected_models/03_model_SVC.json.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Choose the best models to save for each representation.\n",
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"bow\",\n",
    "    classifier_type=\"LogisticRegression\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")\n",
    "\n",
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"bow\",\n",
    "    classifier_type=\"RandomForestClassifier\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")\n",
    "\n",
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"bow\",\n",
    "    classifier_type=\"SVC\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a4a49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/selected_models/04_model_MLPClassifier.json.\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"doc2vec\",\n",
    "    classifier_type=\"MLPClassifier\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca1499fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/selected_models/05_model_RandomForestClassifier.json.\n",
      "/home2/loyola/unsl_erisk_2022/data/processed/reddit/depression/lda/depression_id2word_bigram_model_25topics.pkl\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"lda\",\n",
    "    classifier_type=\"RandomForestClassifier\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "secondary-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model information in /home2/loyola/unsl_erisk_2022/best_models/positive_f1/reddit/depression/selected_models/06_model_LogisticRegression.json.\n",
      "/home2/loyola/unsl_erisk_2022/data/processed/reddit/depression/lsa/depression_id2word_bigram_model_100factors.pkl\n"
     ]
    }
   ],
   "source": [
    "save_best_model(\n",
    "    data=df,\n",
    "    representation=\"lsa\",\n",
    "    classifier_type=\"LogisticRegression\",\n",
    "    corpus_name=CORPUS_NAME,\n",
    "    corpus_kind=CORPUS_KIND,\n",
    "    measure=\"positive_f1\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
