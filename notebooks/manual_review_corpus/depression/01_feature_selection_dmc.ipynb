{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9cc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, mutual_info_classif\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.config import END_OF_POST_TOKEN, PATH_INTERIM_CORPUS  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3655bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = \"depression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = os.path.join(\n",
    "    PATH_INTERIM_CORPUS, f\"xml/{corpus_name}/{corpus_name}-train-raw.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "documents_train = []\n",
    "with open(CORPUS_PATH) as f:\n",
    "    for line in f:\n",
    "        label, document = line.split(maxsplit=1)\n",
    "        label = 1 if label == \"positive\" else 0\n",
    "        labels_train.append(label)\n",
    "        posts = \" \".join(document.split(END_OF_POST_TOKEN))\n",
    "        documents_train.append(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97c5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = {\n",
    "    \"binary\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(**cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_counts = count_vect.fit_transform(documents_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2780f7b",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_01 = SelectPercentile(mutual_info_classif, percentile=0.01)\n",
    "selector_01.fit(x_train_counts, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_selected_01 = selector_01.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48cdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables_01 = []\n",
    "for i, v in enumerate(is_selected_01):\n",
    "    if v:\n",
    "        selected_variables_01.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5f702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = count_vect.get_feature_names()\n",
    "for i in selected_variables_01:\n",
    "    print(vocabulary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8517fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = count_vect.get_feature_names()\n",
    "words_most_information_gain_01 = [vocabulary[i] for i in selected_variables_01]\n",
    "\n",
    "with open(f\"{corpus_name}_information_gain_words.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(fp=fp, obj=words_most_information_gain_01, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72be6ca",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_015_chi2 = SelectPercentile(chi2, percentile=0.015)\n",
    "selector_015_chi2.fit(x_train_counts, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_selected_015_chi2 = selector_015_chi2.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables_015_chi2 = []\n",
    "for i, v in enumerate(is_selected_015_chi2):\n",
    "    if v:\n",
    "        selected_variables_015_chi2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = count_vect.get_feature_names()\n",
    "for i in selected_variables_015_chi2:\n",
    "    print(vocabulary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb6ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = count_vect.get_feature_names()\n",
    "words_chi2_015 = [vocabulary[i] for i in selected_variables_015_chi2]\n",
    "\n",
    "with open(f\"{corpus_name}_chi2_words.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(fp=fp, obj=words_chi2_015, indent=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
