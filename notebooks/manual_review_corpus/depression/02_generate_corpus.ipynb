{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b82cbbc",
   "metadata": {},
   "source": [
    "This notebook will generate the corpus that we'll use to train the new __DMC__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d89f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.config import PATH_BEST_MODELS  # noqa: E402\n",
    "from src.config import PATH_INTERIM_CORPUS  # noqa: E402\n",
    "from src.config import END_OF_POST_TOKEN, PICKLE_PROTOCOL  # noqa: E402\n",
    "from src.models.model import EarlyModel, SimpleStopCriterion  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f22f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_DATASETS_PATH = os.path.join(PATH_INTERIM_CORPUS, \"xml/depression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006140e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_PATH = os.path.join(INTERIM_DATASETS_PATH, \"depression-train-raw.txt\")\n",
    "posts_list = []\n",
    "with open(CORPUS_PATH) as f:\n",
    "    for line in f:\n",
    "        label, posts = line.split(maxsplit=1)\n",
    "        if label == \"positive\":\n",
    "            posts_list.append(posts.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cefd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples where the first element of each tuple is the index of the post in `posts_list` and the second index\n",
    "# represents the manually label point in which the reading should stop.\n",
    "# A value of -1 in the second index means that the users does not seem to be a positive user based on the posts only.\n",
    "reviews = [\n",
    "    (71, 3),\n",
    "    (96, 1),\n",
    "    (108, 23),\n",
    "    (111, 9),\n",
    "    (3, 12),\n",
    "    (113, 36),\n",
    "    (54, 1),\n",
    "    (56, 8),\n",
    "    (104, 1),\n",
    "    (32, 1),\n",
    "    (4, 1),\n",
    "    (99, 117),\n",
    "    (78, 207),\n",
    "    (75, 518),\n",
    "    (118, 196),\n",
    "    (55, 89),\n",
    "    (17, 6),\n",
    "    (125, 21),\n",
    "    (70, 1),\n",
    "    (122, 240),\n",
    "    (126, 1157),\n",
    "    (59, -1),\n",
    "    (16, -1),\n",
    "    (46, -1),\n",
    "    (74, -1),\n",
    "    (24, 5),\n",
    "    (129, 36),\n",
    "    (94, 19),\n",
    "    (97, 26),\n",
    "    (36, 20),\n",
    "    (107, 61),\n",
    "    (58, 38),\n",
    "    (26, -1),\n",
    "    (47, 5),\n",
    "    (69, 13),\n",
    "    (61, 6),\n",
    "    (21, -1),\n",
    "    (28, 109),\n",
    "    (7, -1),\n",
    "    (133, 406),\n",
    "    (132, 11),\n",
    "    (72, 39),\n",
    "    (41, 32),\n",
    "    (20, 55),\n",
    "    (11, 114),\n",
    "    (80, 240),\n",
    "    (76, 12),\n",
    "    (90, -1),\n",
    "    (35, 23),\n",
    "    (77, 6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove users which don't seem positive.\n",
    "reviews = [t for t in reviews if t[1] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167f1f8b",
   "metadata": {},
   "source": [
    "-----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad558a0",
   "metadata": {},
   "source": [
    "Generate a corpus to train the decision tree DMC model.\n",
    "\n",
    "For this corpus, generate a sample for each post `i` from a user.\n",
    "Each sample has all posts up to `i`.\n",
    "\n",
    "Since for some representations, as the number of posts increases the information is \"diluted\", we cannot place the label `1` for all `posts > i` where `i` is the cutoff point. This can cause the model to learn things that are not appropriate.\n",
    "But if we only consider positive those posts where we mark the cutoff point, we will obtain a very unbalanced corpus.\n",
    "Therefore, after the cutoff point, we consider nine post more as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_POSTS_AFTER_STOP_POINT = 9\n",
    "TRAIN_TEST_SPLIT = 0.5\n",
    "TRAIN_SPLIT = int(len(reviews) * TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af93a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dmc_corpus_train = os.path.join(\n",
    "    INTERIM_DATASETS_PATH, \"depression-dmc-train-raw.txt\"\n",
    ")\n",
    "if not os.path.exists(raw_dmc_corpus_train):\n",
    "    for idx, stop_time in reviews[:TRAIN_SPLIT]:\n",
    "        upper_limit = stop_time + NUMBER_POSTS_AFTER_STOP_POINT\n",
    "        current_posts = posts_list[idx].split(END_OF_POST_TOKEN)[: upper_limit + 1]\n",
    "        for i in range(1, min(upper_limit, len(current_posts)) + 1):\n",
    "            label = \"positive\" if i >= stop_time else \"negative\"\n",
    "            concatenated_post = END_OF_POST_TOKEN.join(current_posts[:i])\n",
    "            with open(raw_dmc_corpus_train, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{label}\\t{concatenated_post}\\n\")\n",
    "else:\n",
    "    print(f\"The corpus {raw_dmc_corpus_train} was already created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2232892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dmc_corpus_test = os.path.join(INTERIM_DATASETS_PATH, \"depression-dmc-test-raw.txt\")\n",
    "if not os.path.exists(raw_dmc_corpus_test):\n",
    "    for idx, stop_time in reviews[TRAIN_SPLIT:]:\n",
    "        upper_limit = stop_time + NUMBER_POSTS_AFTER_STOP_POINT\n",
    "        current_posts = posts_list[idx].split(END_OF_POST_TOKEN)[: upper_limit + 1]\n",
    "        for i in range(1, min(upper_limit, len(current_posts)) + 1):\n",
    "            label = \"positive\" if i >= stop_time else \"negative\"\n",
    "            concatenated_post = END_OF_POST_TOKEN.join(current_posts[:i])\n",
    "            with open(raw_dmc_corpus_test, \"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{label}\\t{concatenated_post}\\n\")\n",
    "else:\n",
    "    print(f\"The corpus {raw_dmc_corpus_test} was already created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd0eed",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d5fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"current_probability\",\n",
    "    \"avg_last_10_probabilities\",\n",
    "    \"avg_last_5_probabilities\",\n",
    "    \"median_last_10_probabilities\",\n",
    "    \"current_delay\",\n",
    "    \"num_words_information_gain_percentile_0_01\",\n",
    "    \"num_words_chi2_percentile_0_015\",\n",
    "    \"current_cpi_decision\",\n",
    "    \"avg_last_10_cpi_decision\",\n",
    "]\n",
    "\n",
    "dmc_corpus_feature_names = os.path.join(\n",
    "    INTERIM_DATASETS_PATH, \"depression-dmc-feature-names.json\"\n",
    ")\n",
    "with open(dmc_corpus_feature_names, \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump(fp=fp, obj=feature_names, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e452b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"depression_information_gain_words.json\") as fp:\n",
    "    depression_information_gain_words = json.load(fp=fp)\n",
    "\n",
    "with open(\"depression_chi2_words.json\") as fp:\n",
    "    depression_chi2_words = json.load(fp=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model to obtain the probabilities of the partial inputs.\n",
    "# TODO: You need to update this.\n",
    "model_path = os.path.join(\n",
    "    PATH_BEST_MODELS, \"positive_f1/reddit/depression/selected_models/03_model_SVC.json\"\n",
    ")\n",
    "\n",
    "simple_criterion = SimpleStopCriterion(threshold=0.07, min_delay=1)\n",
    "\n",
    "model = EarlyModel(\n",
    "    path_to_model_information=model_path, stop_criterion=simple_criterion\n",
    ")\n",
    "model.clear_model_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "x_train = []\n",
    "groups_train = []\n",
    "for idx, stop_time in reviews[:TRAIN_SPLIT]:\n",
    "    last_probabilities = []\n",
    "    last_decisions = []\n",
    "    upper_limit = stop_time + NUMBER_POSTS_AFTER_STOP_POINT\n",
    "    current_posts = posts_list[idx].split(END_OF_POST_TOKEN)[: upper_limit + 1]\n",
    "    for i in range(1, min(upper_limit, len(current_posts)) + 1):\n",
    "        label = 1 if i >= stop_time else 0\n",
    "        y_train.append(label)\n",
    "        raw_post = \" \".join(current_posts[:i])\n",
    "        concatenated_post = END_OF_POST_TOKEN.join(current_posts[:i])\n",
    "        model.predict(documents_test=[concatenated_post], delay=i)\n",
    "        predictions = model.predictions\n",
    "        scores = model.probabilities\n",
    "        if len(last_probabilities) < 10:\n",
    "            last_probabilities.append(scores.item())\n",
    "            last_decisions.append(predictions.item())\n",
    "        else:\n",
    "            last_probabilities = last_probabilities[1:] + [scores.item()]\n",
    "            last_decisions = last_decisions[1:] + [predictions.item()]\n",
    "        current_features = [\n",
    "            scores.item(),  # CURRENT_PROBABILITY\n",
    "            np.average(last_probabilities).item(),  # AVG_LAST_10_PROBABILITIES\n",
    "            np.average(last_probabilities[-5:]).item(),  # AVG_LAST_5_PROBABILITIES\n",
    "            np.median(last_probabilities).item(),  # MEDIAN_LAST_10_PROBABILITIES\n",
    "            i,  # CURRENT_DELAY\n",
    "            sum(\n",
    "                1 if w in depression_information_gain_words else 0\n",
    "                for w in raw_post.split()\n",
    "            ),  # NUM_WORDS_INFORMATION_GAIN_PERCENTILE_0_01\n",
    "            sum(\n",
    "                1 if w in depression_chi2_words else 0 for w in raw_post.split()\n",
    "            ),  # NUM_WORDS_CHI2_PERCENTILE_0_015\n",
    "            predictions.item(),  # CURRENT_CPI_DECISION\n",
    "            np.average(last_decisions).item(),  # AVG_LAST_10_CPI_DECISION\n",
    "        ]\n",
    "        x_train.append(current_features)\n",
    "        groups_train.append(idx)\n",
    "        model.clear_model_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_pos_train = {}\n",
    "for i, idx in enumerate(groups_train):\n",
    "    if idx not in cant_pos_train:\n",
    "        cant_pos_train[idx] = 0\n",
    "    cant_pos_train[idx] += y_train[i]\n",
    "cant_pos_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5359fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3662c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmc_corpus_train = os.path.join(INTERIM_DATASETS_PATH, \"depression-dmc-train.pkl\")\n",
    "with open(dmc_corpus_train, \"wb\") as fp:\n",
    "    pickle.dump((x_train, y_train, groups_train), fp, protocol=PICKLE_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ce5c8",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7104b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "x_test = []\n",
    "groups_test = []\n",
    "for idx, stop_time in reviews[TRAIN_SPLIT:]:\n",
    "    last_probabilities = []\n",
    "    last_decisions = []\n",
    "    upper_limit = stop_time + NUMBER_POSTS_AFTER_STOP_POINT\n",
    "    current_posts = posts_list[idx].split(END_OF_POST_TOKEN)[: upper_limit + 1]\n",
    "    for i in range(1, min(upper_limit, len(current_posts)) + 1):\n",
    "        label = 1 if i >= stop_time else 0\n",
    "        y_test.append(label)\n",
    "        raw_post = \" \".join(current_posts[:i])\n",
    "        concatenated_post = END_OF_POST_TOKEN.join(current_posts[:i])\n",
    "        model.predict(documents_test=[concatenated_post], delay=i)\n",
    "        predictions = model.predictions\n",
    "        scores = model.probabilities\n",
    "        if len(last_probabilities) < 10:\n",
    "            last_probabilities.append(scores.item())\n",
    "            last_decisions.append(predictions.item())\n",
    "        else:\n",
    "            last_probabilities = last_probabilities[1:] + [scores.item()]\n",
    "            last_decisions = last_decisions[1:] + [predictions.item()]\n",
    "        current_features = [\n",
    "            scores.item(),  # CURRENT_PROBABILITY\n",
    "            np.average(last_probabilities).item(),  # AVG_LAST_10_PROBABILITIES\n",
    "            np.average(last_probabilities[-5:]).item(),  # AVG_LAST_5_PROBABILITIES\n",
    "            np.median(last_probabilities).item(),  # MEDIAN_LAST_10_PROBABILITIES\n",
    "            i,  # CURRENT_DELAY\n",
    "            sum(\n",
    "                1 if w in depression_information_gain_words else 0\n",
    "                for w in raw_post.split()\n",
    "            ),  # NUM_WORDS_INFORMATION_GAIN_PERCENTILE_0_01\n",
    "            sum(\n",
    "                1 if w in depression_chi2_words else 0 for w in raw_post.split()\n",
    "            ),  # NUM_WORDS_CHI2_PERCENTILE_0_015\n",
    "            predictions.item(),  # CURRENT_CPI_DECISION\n",
    "            np.average(last_decisions).item(),  # AVG_LAST_10_CPI_DECISION\n",
    "        ]\n",
    "        x_test.append(current_features)\n",
    "        groups_test.append(idx)\n",
    "        model.clear_model_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_pos_test = {}\n",
    "for i, idx in enumerate(groups_test):\n",
    "    if idx not in cant_pos_test:\n",
    "        cant_pos_test[idx] = 0\n",
    "    cant_pos_test[idx] += y_test[i]\n",
    "cant_pos_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71253255",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "groups_test = np.array(groups_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab2ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmc_corpus_test = os.path.join(INTERIM_DATASETS_PATH, \"depression-dmc-test.pkl\")\n",
    "with open(dmc_corpus_test, \"wb\") as fp:\n",
    "    pickle.dump((x_test, y_test, groups_test), fp, protocol=PICKLE_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
